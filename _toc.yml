# Table of contents
#
# possible external link:
# - url: http://espn.com 
#
# Can override a title:
# title: A special title  
#
# Learn more at https://jupyterbook.org/customize/toc.html
#
#################################################
# next year
#
# rename About the class --> Syllabus 
#
# add the coursesite job hunting resource 
#
# see comments below for tweaks and additions
# more exercises for sure
#
# remove most (all) survey links, very little feedback received
#
# record all lectures and keep posted all semester, just incentivize live watching directly
#
# pre-class 
#    set up video for anaconda et al 
#    send some python tutorial 
#
# add 5.5: finance applications. 
# should have pages with "canonical asset pricing", a loan pricing model
#
# new data ideas:
# lending club data?
# ESG - ???
# GUSTAFSON ET AL SEA RISE - environmental 
# night lights/parking lot photos
# crypto something? robo advising? 
# 
#################################################

- file: content/frontpage # the index must be a single file, no way around it!


- part: About the class
  chapters:
  - file: content/about/objectives
  - file: content/about/outcomes
    title: "Outcomes"
  - file: content/about/about_us
    title: "About us + office hours" 
  - file: content/about/structure_and_policies
  - file: content/about/gradeoverview
  - file: content/about/acknowledgments
  
# - part: Schedule, tips, resources
  # chapters:
  # - file: content/about/schedule
    # title: "Dashboard, key links, schedule"
  # - file: content/about/resources
    # title: "Help + resources"
  # - file: content/about/tips


# - part: Assignments and participation  
  # chapters:
  # - file: content/assignments/howto_do
    # title: "How to start and turn in assignments"
  # - file: content/assignments/howto_review 
    # title: "How to do your peer reviews"
  # - file: content/assignments/asgn_5 
    # title: "ASGN 5: Our first full data science assignment"
  # - file: content/assignments/project 
    # title: "Final projects"

# This MD files can be copied into repo, but remove the dropdowns. And link to the website. 
# PROPOSAL DUE APR 21 5pm. STATUS REPORT DUE APR 28. 
  
# - part: Textbook 
  # numbered: true # will number the chapters and sections INSIDE the part(s) below
  # chapters:  
  # - file: "content/01/00_Getting_Started"
    # title: "Motivation and Getting Started"
    # sections:
    # - file: "content/01/01_Motivation"
      # title: "Motivation"
    # - file: "content/01/02_Setup"
    # - file: "content/01/03_github"
    # - file: "content/01/04_Markdown"
    # - file: "content/01/05_jupyterlab"
      # title: "Jupyter Lab Basics"    
    # - file: "content/01/06_python"
      # title: "Python Basics"    
    # - file: "content/01/07_debugging"
      # title: "Debugging"    
    # - file: "content/01/07a_errors"
    # - file: "content/01/08_libraries"
    # - file: "content/01/09_gitignore"
      # title: "Gitignore Files"    
    
  # - file: "content/02/10_Golden_1"
    # title: "Good Analysis Practices"
    # sections:
    # - file: "content/02/10_Golden_2"
      # title: "A case study of bad research"
    # - file: "content/02/10_Golden_3"
      # title: "The golden rules"
    # - file: "content/02/10_Golden_4"
      # title: "Good data"
    # - file: "content/02/10_Golden_5"
      # title: "When to write functions"
    # - file: "content/02/10_Golden_6"
      # title: "Reorganizing the bad research folder"
    # - file: "content/02/10_Golden_7"
      # title: "Filepaths"
    
  # - file: "content/03/00_Data_Wrangling_Intro"
    # title: "Wrangling with Data"
    # sections:
    # - file: "content/03/01_Numpy"
      # title: "Numpy"
      # sections:
        # - file: "content/03/01a_NumpyCS"
          # title: "Numpy + Scientific Computing"
        # - file: "content/03/01b_NumpyBasics"
          # title: "A (Very) Short Introduction"
        # - file: "content/03/01c_NumpyPractice"
          # title: "Exercises"
        # - file: "content/03/01d_NumpyResources"
          # title: "More Resources"
    # - file: "content/03/02a_pandasIntro"
      # title: "Pandas"
      # sections:
        # - file: "content/03/02a_pandasTips"
          # title: "Tips"      
        # - file: "content/03/02b_pandasVocab"
          # title: "Vocab and Long vs Wide Data"      
        # - file: "content/03/02c_commonFcns"
          # title: "Common Functions"      
        # - file: "content/03/02d_temp"
          # title: "Temp. vs Perm. Objects"      
        # - file: "content/03/02e_eda_golden"
          # title: "Golden Rules + EDA"      
        # - file: "content/03/02f_chains"
          # title: "Pandas Chains" 
        # - file: "content/03/02g_commontasks"
          # title: "Common Tasks" 
        # - file: "content/03/02h_exercises"
          # title: "Exercises" 
        # - file: "content/03/02j_resourcesAndSum"
          # title: "Summary and Resources" 
    # - file: "content/03/04a-dataviz"
      # title: "Data Visualization"
      # sections:
        # - file: "content/03/04b-whyplot"
        # - file: "content/03/04c-makeplot"
        # - file: "content/03/04d-whichplot"
        # - file: "content/03/04e-visualEDA"
        # - file: "content/03/04f-betterplots"
#        - file: "content/03/04g-lyingfigures"
# Add as note in toc for next years stats pic
# otis_reid (@Otis Reid) Tweeted: Good article about disbelief being at the root of belief in conspiracy theories from @TimHarford â€” did not know this bit before! https://t.co/1UlLs43STg https://twitter.com/otis_reid/status/1389707199837097988?s=27
    # - file: "content/03/05a-otherskills"
      # sections:
        # - file: "content/03/05b_merging"
        # - file: "content/03/05c_missingdata"
        # - file: "content/03/05d_outliers"
     
  # - file: "content/04/00_World_Wide_Data"
    # title: "Accessing the World of Data"
    # sections:
    # - file: "content/04/01_Intro_to_scraping"
      # title: "Getting Data off the Web"
    # - file: "content/04/01a_openingAndParsing"
    # - file: "content/04/01b_spiders"
      # title: "Building a spider" 
    # - file: "content/04/02_strings"
      # sections:
        # - file: "content/04/02a_Python Strings"
        # - file: "content/04/02b_regex"
        # - file: "content/04/02c_developing a regex"
        # - file: "content/04/02d_RegexApplication"
# now that they can scrape, a new world opens up: https://sec-edgar-downloader.readthedocs.io/en/latest/#quick-start        

  # - file: "content/05/00_intro"
    # title: "Data Science for Finance"    
    # sections:
    # - file: "content/05/01_bigpicture"
      # sections:
        # - file: "content/05/01a_MLgonewrong"    
        # - file: "content/05/01b_model_process"
        # - file: "content/05/01c_teams"
        # - file: "content/05/01d_sharingBigFiles"
    # - file: "content/05/02_reg"
      # sections:
        # - file: "content/05/02a_basics"    
        # - file: "content/05/02b_mechanics"
        # - file: "content/05/02c_goodnessOfFit"      
        # - file: "content/05/02d_interpretingCoefs" 
        # - file: "content/05/02e_statisticalSig"     
        # # (opt, future?) selection, measurement, omitted variables (HIGH level)
        # # (opt, future?) exercises (and answers)
        # - file: "content/05/02g_summary"           
    # - file: "content/05/03_ML"
      # sections:
        # - file: "content/05/03a_ML_obj_and_tradeoff"    
        # - file: "content/05/03c_ModelEval" 
        # - file: "content/05/03c1_OOS"  
        # - file: "content/05/03d_whatToMax"   # need auc/roc
        # - file: "content/05/03e_whichModel"  # need lots more!   
        # - file: "content/05/03f_leakage"  
    # - file: "content/05/04a_SKLearn"        
      # sections:
        # - file: "content/05/04b_best_practices" # add extra section for best practices
          # title: "Best Practice Pseudo Code"        
        # - file: "content/05/04c_onemodel"
          # title: "SKLearn Intro"                             
        # - file: "content/05/04d_crossval"
          # title: "Cross-Validation"
        # - file: "content/05/04e_pipelines"
          # title: "Pipelines"
        # - file: "content/05/04e1_preprocessing"
          # title: "Preprocessing"  
        # - file: "content/05/04f_optimizing_a_model"
          # title: "Optimizing a Model"            
        # - file: "content/05/04h_putting_together"
          # title: "Many Models" 
# import smattering? (from below)
# gradient booksting from L24 2020
    # - file: "content/05/05_thefuture"              
      # sections:
        # - file: "content/05/05_saving"    



# #########################################################


# # ## A bunch of import statements 

# # Any code you write might use none of these, some of these, or all of them!

# # # dataset loader
# # from sklearn import datasets

# # # model training and evalutation utilities 
# # from sklearn.model_selection import train_test_split
# # from sklearn.model_selection import cross_validate, GridSearchCV
# # from sklearn.model_selection import StratifiedKFold # this is one way to generate folds
# # from sklearn.model_selection import KFold

# # # metrics
# # from sklearn import metrics
# # from sklearn.metrics import r2_score
# # from sklearn.metrics import accuracy_score
# # from sklearn.metrics import classification_report
# # from sklearn.metrics import confusion_matrix

# # # preprocessing and feature extraction
# # from sklearn.pipeline import Pipeline, make_pipeline
# # from sklearn.compose import ColumnTransformer, make_column_selector
# # from sklearn import preprocessing
# # from sklearn.preprocessing import StandardScaler, OneHotEncoder
# # from sklearn.feature_extraction import DictVectorizer
# # from sklearn.impute import SimpleImputer
# # from df_after_transform import df_after_transform # df_after_transform.py must be in this folder

# # # feature selection
# # from sklearn.linear_model import ElasticNet, Lasso, Ridge
# # from sklearn.feature_selection import SelectKBest, RFE, RFECV,

# # # models
# # from sklearn.svm import SVC
# # from sklearn.neighbors import KNeighborsClassifier
# # from sklearn.linear_model import LinearRegression
# # from sklearn import linear_model
# # from sklearn.linear_model import LogisticRegression
# # from sklearn.tree import DecisionTreeClassifier
# # from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
# # from sklearn.naive_bayes import GaussianNB

# # # toy data
# # X, y = datasets.load_iris(return_X_y=True)
# # X.shape, y.shape



####################

# l23 exercises 
# 
# reg with some vars, then Add 5 new continuous variables to your pipeline and see how the R2 changes
#
# implement rfecv - what vars should we choose? implement
